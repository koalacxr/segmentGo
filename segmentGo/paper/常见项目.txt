SCWS

Hightman开发的一套基于词频词典的机械中文分词引擎，它能将一整段的汉字基本正确的切分成词。采用的是采集的词频词典，并辅以一定的专有名称，人名，地名，数字年代等规则识别来达到基本分词，经小范围测试大概准确率在 90% ~ 95% 之间，已能基本满足一些小型搜索引擎、关键字提取等场合运用。45Kb左右的文本切词时间是0.026秒，大概是1.5MB文本/秒，支持PHP4和PHP 5。
FudanNLP

FudanNLP主要是为中文自然语言处理而开发的工具包，也包含为实现这些任务的机器学习算法和数据集。本工具包及其包含数据集使用LGPL3.0许可证。开发语言为Java。功能包括中文分词等，不需要字典支持。
ICTCLAS

这是最早的中文开源分词项目之一，ICTCLAS在国内973专家组组织的评测中活动获得了第一名，在第一届国际中文处理研究机构SigHan组织的评测中都获得了多项第一名。ICTCLAS3.0分词速度单机996KB/s，分词精度98.45%，API不超过200KB，各种词典数据压缩后不到3M.ICTCLAS全部采用C/C++编写，支持Linux、FreeBSD及Windows系列操作系统，支持C/C++、C#、Delphi、Java等主流的开发语言。
HTTPCWS

HTTPCWS 是一款基于HTTP协议的开源中文分词系统，目前仅支持Linux系统。HTTPCWS 使用“ICTCLAS 3.0 2009共享版中文分词算法”的API进行分词处理，得出分词结果。HTTPCWS 将取代之前的 PHPCWS 中文分词扩展。
CC-CEDICT

一个中文词典开源项目，提供一份以汉语拼音为中文辅助的汉英辞典，截至2009年2月8日，已收录82712个单词。其词典可以用于中文分词使用，而且不存在版权问题。Chrome中文版就是使用的这个词典进行中文分词的。
IK

IKAnalyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IKAnalyzer3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。
Paoding

Paoding（庖丁解牛分词）基于Java的开源中文分词组件，提供lucene和solr 接口，具有极 高效率和 高扩展性。引入隐喻，采用完全的面向对象设计，构思先进。
高效率：在PIII 1G内存个人机器上，1秒可准确分词 100万汉字。
采用基于 不限制个数的词典文件对文章进行有效切分，使能够将对词汇分类定义。
能够对未知的词汇进行合理解析。
仅支持Java语言。
MMSEG4J

MMSEG4J基于Java的开源中文分词组件，提供lucene和solr 接口：
1．mmseg4j 用 Chih-Hao Tsai 的 MMSeg 算法实现的中文分词器，并实现 lucene 的 analyzer 和 solr 的TokenizerFactory 以方便在Lucene和Solr中使用。
2．MMSeg 算法有两种分词方法：Simple和Complex，都是基于正向最大匹配。Complex 加了四个规则过虑。官方说：词语的正确识别率达到了 98.41%。mmseg4j 已经实现了这两种分词算法。
盘古分词

盘古分词是一个基于.net 平台的开源中文分词组件，提供lucene(.net 版本) 和HubbleDotNet的接口
高效：Core Duo 1.8 GHz 下单线程 分词速度为 390K 字符每秒
准确：盘古分词采用字典和统计结合的分词算法，分词准确率较高。
功能：盘古分词提供中文人名识别，简繁混合分词，多元分词，英文词根化，强制一元分词，词频优先分词，停用词过滤，英文专名提取等一系列功能。
Jcseg

jcseg是使用Java开发的一个中文分词器，使用流行的mmseg算法实现。[2]
1。mmseg四种过滤算法，分词准确率达到了98.4%以上。
2。支持自定义词库。在lexicon文件夹下，可以随便添加/删除/更改词库和词库内容，并且对词库进行了分类，词库整合了《现代汉语词典》和cc-cedict辞典。
3。词条拼音和同义词支持，jcseg为所有词条标注了拼音，并且词条可以添加同义词集合，jcseg会自动将拼音和同义词加入到分词结果中。
4。中文数字和分数识别，例如："四五十个人都来了，三十分之一。"中的"四五十"和"三十分之一"，并且jcseg会自动将其转换为对应的阿拉伯数字。
5。支持中英混合词的识别。例如：B超，x射线。
6。支持基本单字单位的识别，例如2012年。
7。良好的英文支持，自动识别电子邮件，网址，分数，小数，百分数……。
8。智能圆角半角转换处理。
9。特殊字母识别：例如：Ⅰ，Ⅱ
10。特殊数字识别：例如：①，⑩
11。配对标点内容提取：例如：最好的Java书《java编程思想》，‘畅想杯黑客技术大赛’，被《,‘,“,『标点标记的内容。
12。智能中文人名识别。中文人名识别正确率达94%以上。
jcseg佩带了jcseg.properties配置文档，使用文本编辑器就可以自主的编辑其选项，配置适合不同应用场合的分词应用。例如：最大匹配分词数，是否开启中文人名识别，是否载入词条拼音，是否载入词条同义词……。
friso

friso是使用c语言开发的一个中文分词器，使用流行的mmseg算法实现。完全基于模块化设计和实现，可以很方便的植入到其他程序中，例如：MySQL，PHP等。并且提供了一个php中文分词扩展robbe。
1。只支持UTF-8编码。【源码无需修改就能在各种平台下编译使用，加载完20万的词条，内存占用稳定为14M。】。
2。mmseg四种过滤算法，分词准确率达到了98.41%。
3。支持自定义词库。在dict文件夹下，可以随便添加/删除/更改词库和词库词条，并且对词库进行了分类。
4。词库使用了friso的Java版本jcseg的简化词库。
5。支持中英混合词的识别。例如：c语言，IC卡。
7。很好的英文支持，电子邮件，网址，小数，分数，百分数。
8。支持阿拉伯数字基本单字单位的识别，例如2012年，5吨，120斤。
9。自动英文圆角/半角，大写/小写转换。
并且具有很高的分词速度：简单模式：3.7M/秒，复杂模式：1.8M/秒。[3]